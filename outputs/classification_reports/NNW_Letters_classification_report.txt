              precision    recall  f1-score   support

           A       0.59      0.58      0.59        50
           B       0.77      0.66      0.71        50
           C       0.91      0.42      0.58        50
           D       0.68      0.50      0.57        50
           E       0.97      0.58      0.72        50
           F       0.83      0.98      0.90        50
           G       0.71      0.90      0.80        50
           H       1.00      0.60      0.75        50
           I       0.68      0.56      0.62        50
           J       0.69      0.74      0.71        50
           K       0.75      0.96      0.84        50
           L       0.63      0.76      0.69        50
           M       0.75      1.00      0.85        50
           N       1.00      0.78      0.88        50
           O       0.58      0.42      0.49        50
           P       0.77      1.00      0.87        50
           Q       0.74      1.00      0.85        50
           R       0.61      0.98      0.75        50
           S       0.98      0.94      0.96        50
           T       0.83      0.86      0.84        50
           U       1.00      0.66      0.80        50
           V       0.64      0.64      0.64        50
           W       0.61      0.84      0.71        50
           X       0.97      0.72      0.83        50
           Y       0.73      0.60      0.66        50
           Z       0.81      1.00      0.89        50

    accuracy                           0.76      1300
   macro avg       0.78      0.76      0.75      1300
weighted avg       0.78      0.76      0.75      1300


Precision: How many times the prediction was right (for each letter)
Recall: How many times the model was right when the real letter was this one (for each letter)
F1-Score: Harmonic mean between precision and recall
Support: Real samples (of each letter)
Macro Average: Metrics simple mean (all letters have the same weight)
Weighted Average: mean based on letter support
