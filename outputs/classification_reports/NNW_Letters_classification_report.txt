              precision    recall  f1-score   support

           A       0.71      0.67      0.69        15
           B       1.00      0.73      0.85        15
           C       0.60      0.40      0.48        15
           D       0.75      0.40      0.52        15
           E       0.90      0.60      0.72        15
           F       0.79      1.00      0.88        15
           G       0.85      0.73      0.79        15
           H       0.82      0.60      0.69        15
           I       0.43      0.20      0.27        15
           J       0.60      0.80      0.69        15
           K       0.73      0.73      0.73        15
           L       0.65      0.87      0.74        15
           M       0.70      0.93      0.80        15
           N       1.00      0.80      0.89        15
           O       0.62      0.53      0.57        15
           P       0.75      1.00      0.86        15
           Q       0.71      1.00      0.83        15
           R       0.43      1.00      0.60        15
           S       0.94      1.00      0.97        15
           T       1.00      0.93      0.97        15
           U       1.00      0.60      0.75        15
           V       0.71      0.67      0.69        15
           W       0.94      1.00      0.97        15
           X       1.00      0.53      0.70        15
           Y       0.69      0.60      0.64        15
           Z       0.71      1.00      0.83        15

    accuracy                           0.74       390
   macro avg       0.77      0.74      0.74       390
weighted avg       0.77      0.74      0.74       390


Precision: How many times the prediction was right (for each letter)
Recall: How many times the model was right when the real letter was this one (for each letter)
F1-Score: Harmonic mean between precision and recall
Support: Real samples (of each letter)
Macro Average: Metrics simple mean (all letters have the same weight)
Weighted Average: mean based on letter support
