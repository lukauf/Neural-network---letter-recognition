              precision    recall  f1-score   support

           A       0.57      0.80      0.67         5
           B       1.00      0.80      0.89         5
           C       1.00      0.60      0.75         5
           D       1.00      0.60      0.75         5
           E       1.00      0.60      0.75         5
           F       0.71      1.00      0.83         5
           G       0.67      0.80      0.73         5
           H       1.00      0.60      0.75         5
           I       0.71      1.00      0.83         5
           J       1.00      0.80      0.89         5
           K       0.80      0.80      0.80         5
           L       0.75      0.60      0.67         5
           M       0.57      0.80      0.67         5
           N       1.00      0.80      0.89         5
           O       0.67      0.40      0.50         5
           P       1.00      1.00      1.00         5
           Q       0.83      1.00      0.91         5
           R       0.56      1.00      0.71         5
           S       0.83      1.00      0.91         5
           T       1.00      1.00      1.00         5
           U       1.00      0.80      0.89         5
           V       0.67      0.40      0.50         5
           W       0.71      1.00      0.83         5
           X       1.00      0.67      0.80         6
           Y       0.83      0.83      0.83         6
           Z       0.75      1.00      0.86         6

    accuracy                           0.80       133
   macro avg       0.83      0.80      0.79       133
weighted avg       0.83      0.80      0.79       133


Precision: How many times the prediction was right (for each letter)
Recall: How many times the model was right when the real letter was this one (for each letter)
F1-Score: Harmonic mean between precision and recall
Support: Real samples (of each letter)
Macro Average: Metrics simple mean (all letters have the same weight)
Weighted Average: mean based on letter support
